{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kinase_library as kl\n",
    "testsequence='PSVEPPLsQETFSDL'\n",
    "\n",
    "# Create a Substrate object with a target sequence (example: p53 S33)\n",
    "s = kl.Substrate(testsequence)  # Lowercase 's' indicates a phosphoserine\n",
    "\n",
    "# Predict potential kinase interactions for the substrate\n",
    "s.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task 1 - to write code mutating first amino acid to every other possible amino acid\"\"\"\n",
    "#how to replace one letter for another in test sequence.\n",
    "\n",
    "#how to replace one letter for each amino acid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutated_sequences = [] #creates a list to store the mutated amino acids\n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"  # defines the standard 20 amino acids\n",
    "for i, original_aa in enumerate(testsequence): #indexes the original amino acids \n",
    "    for new_aa in amino_acids: #creates a loop of all amino acids\n",
    "        if new_aa != original_aa:  # Avoid replacing with itself\n",
    "                mutated_seq = testsequence[:i] + new_aa + testsequence[i+1:] #creates a new sequence (mutated seq)\n",
    "                mutated_sequences.append(mutated_seq) #stores mutated sequence\n",
    "\n",
    "print(f'Mutated sequences (# sequences = {len(mutated_sequences)})')\n",
    "print(mutated_sequences)\n",
    " #shows mutations at each position\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task2 - Run these sequences through the predict function and store the output as a csv file. Look at pandas.to_csv() for this.\n",
    "Output should be 280 separate csv files. Don't worry about a naming convention yet. \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"mutations\", exist_ok=True)\n",
    "#creates a new folder called mutations to put the sequence predictions into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kinase_library as kl\n",
    "import pandas as pd\n",
    "\n",
    "testsequence = 'PSVEPPLsQETFSDL'  \n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "mutated_sequences = []  \n",
    "wild_type_filename = f\"mutations/wildtype.csv\"\n",
    "\n",
    "\n",
    "# Predict kinase data for the wild-type sequence\n",
    "try:\n",
    "    wild_type_substrate = kl.Substrate(testsequence)\n",
    "    wild_type_predictions = wild_type_substrate.predict()\n",
    "\n",
    "    # Save wild-type predictions to CSV\n",
    "    df_wild_type = pd.DataFrame(wild_type_predictions)\n",
    "    df_wild_type.to_csv(wild_type_filename, index=False)\n",
    "\n",
    "    print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "for i, original_aa in enumerate(testsequence):  \n",
    "    for new_aa in amino_acids:\n",
    "        if new_aa != original_aa:  \n",
    "                mutated_seq = testsequence[:i] + new_aa + testsequence[i+1:] \n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))  \n",
    "\n",
    "\n",
    "print(f\"Total mutations generated: {len(mutated_sequences)}\") \n",
    "\n",
    "for i, original_aa, new_aa, mutated_seq in mutated_sequences: \n",
    "    try:\n",
    "        s = kl.Substrate(mutated_seq)\n",
    "        predictions = s.predict()\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(predictions)\n",
    "\n",
    "        # Save to CSV file with a structured name\n",
    "        filename = f\"mutations/mutation_Pos{i}_{original_aa}_to_{new_aa}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping mutation at position {i} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task3 - Run through the 286 csv files and extract the order of the kinases. Then using the test sequence as the reference.\n",
    "Compute a metric for each pair using something similar to LCS (link for inspo attached - https://chatgpt.com/share/67c705a9-9c74-8001-a8da-eac57f06384f)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "#This extracts the kinase orders from 269 files - one being the reference sequence.\n",
    "#I assume some mutations at position 7 are skipped due to the lack of phosphoacceptor.\n",
    "#So giving 18 fewer LCS scores compared to the number of CSV files generated earlier.\n",
    "#This is consistent with the data shown on the heatmap in the next cell.\n",
    "\n",
    "mut_predictions = \"mutations/\"\n",
    "\n",
    "wildtype_path = os.path.join(mut_predictions, \"wildtype.csv\")\n",
    "\n",
    "df_wildtype = pd.read_csv(wildtype_path)\n",
    "\n",
    "wildtype_kinase_order = df_wildtype[\"Score Rank\"].tolist()  #extracts kinase orders from the reference sequence\n",
    "\n",
    "kinase_orders = {}\n",
    "\n",
    "#reads all files to extract the kinase orders (except wildtype as that's already been done)\n",
    "for file in os.listdir(mut_predictions):\n",
    "    if file.endswith(\".csv\") and file != \"wildtype.csv\":\n",
    "        file_path = os.path.join(mut_predictions, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if \"Score Rank\" in df.columns:\n",
    "                kinase_orders[file] = df[\"Score Rank\"].tolist()  # Store kinase order\n",
    "            else:\n",
    "                print(f\"Skipping {file}: No 'Score Rank' column found.\") \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")   #debugging steps\n",
    "\n",
    "print(f\"Extracted kinase orders from {len(kinase_orders)} mutation CSVs.\") \n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "#finds the LCS between wildtype and mut seqs\n",
    "lcs_scores = {}\n",
    "for file, order in kinase_orders.items():\n",
    "    lcs_length = longest_common_subsequence(order, wildtype_kinase_order)\n",
    "    lcs_scores[file] = lcs_length\n",
    "\n",
    "#normalizes LCS scores between 0 and 1\n",
    "if lcs_scores:\n",
    "    lcs_min = min(lcs_scores.values())\n",
    "    lcs_max = max(lcs_scores.values())\n",
    "\n",
    "    normalized_lcs = {file: (score - lcs_min) / (lcs_max - lcs_min) for file, score in lcs_scores.items()}\n",
    "\n",
    "   \n",
    "    df_lcs = pd.DataFrame(list(normalized_lcs.items()), columns=['Mutation_File', 'Normalized_LCS'])\n",
    "    \n",
    "    print(\"\\nNormalized LCS Scores:\")\n",
    "    print(df_lcs.sort_values(by=\"Normalized_LCS\", ascending=True))  # Sort by lowest LCS\n",
    "\n",
    "else:\n",
    "    print(\"No LCS scores calculated. Ensure kinase_orders contains data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 4: generate heatmaps of LCS ratio for each mutation on the y axis and position on the x axis. I like plotly heatmaps for this\n",
    "https://plotly.com/python/heatmaps/. So output will be a heat map showing hotspots for the mutations that disrup the phosphorylation motif the most\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "lcs_data = []\n",
    "\n",
    "for file, normalized_score in normalized_lcs.items():\n",
    "    \n",
    "    match = re.match(r\"mutation_Pos(\\d+)_\\w+_to_(\\w+)\\.csv\", file)\n",
    "\n",
    "    if match:\n",
    "        position = int(match.group(1)) \n",
    "        mutated_aa = match.group(2)  \n",
    "\n",
    "        lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "\n",
    "df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "\n",
    "\n",
    "heatmap_matrix = df_lcs.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio')\n",
    "\n",
    "\n",
    "fig = px.imshow(\n",
    "    heatmap_matrix,\n",
    "    labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "    color_continuous_scale='Temps',\n",
    "    title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    ")\n",
    "\n",
    "# Format axes\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "        dtick=1  # Show every position\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='linear',\n",
    "        dtick=1  # Show every position\n",
    "    ),\n",
    "    coloraxis_colorbar=dict(\n",
    "        tickvals=[0, 0.25, 0.5, 0.75, 1],  # Set scale from 0 to 1\n",
    "        ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"]\n",
    "    ),\n",
    "    plot_bgcolor='white'  \n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate tables and subplots showing cases for high and low LCS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths and variables\n",
    "mut_predictions = \"C:/Users/ricea/OneDrive/Documents/GitHub/Annabel-BSc-Project/mutations\"\n",
    "kinase_orders = {}\n",
    "mutated_sequences = []\n",
    "\n",
    "def extract_mutated_sequences():\n",
    "    \"\"\"Reads CSV files and extracts mutated sequences from the file names.\"\"\"\n",
    "    global mutated_sequences\n",
    "    for file in os.listdir(mut_predictions):  # Finds the CSVs, reads the CSVs\n",
    "        if file.endswith(\".csv\") and file != \"wildtype.csv\":  # Exclude wildtype.csv\n",
    "            # Extract position, original amino acid, and new amino acid from the file name\n",
    "            parts = file.split('_')\n",
    "            original_aa = parts[2]  # This is the original amino acid\n",
    "            new_aa = parts[4].split('.')[0]  # This is the new amino acid (without \".csv\")\n",
    "            \n",
    "            # Store mutated sequence information (e.g., \"P_to_A\")\n",
    "            mutated_sequence = f\"{original_aa}_to_{new_aa}\"\n",
    "            mutated_sequences.append(mutated_sequence)  # Store mutated sequence\n",
    "\n",
    "    print(f\"Extracted {len(mutated_sequences)} mutated sequences from filenames.\")  # Checks if it's done\n",
    "\n",
    "def extract_kinase_orders():\n",
    "    \"\"\"Reads CSV files and extracts kinase orders.\"\"\"\n",
    "    global kinase_orders\n",
    "    for file in os.listdir(mut_predictions):  # Finds the CSVs, reads the CSVs\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(mut_predictions, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Check if \"Score Rank\" column exists\n",
    "                if \"Score Rank\" in df.columns:\n",
    "                    kinase_list = df[\"Score Rank\"].tolist()\n",
    "                    kinase_orders[file] = kinase_list  # Store kinase order for each mutation\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'Score Rank' column found.\")  # Proofreads\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")  # Proofreads\n",
    "\n",
    "    print(f\"Extracted kinase orders from {len(kinase_orders)} CSV files.\")  # Checks if it's done\n",
    "\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    \"\"\"Computes the Longest Common Subsequence (LCS) length between two lists.\"\"\"\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "def calculate_lcs_scores():\n",
    "    \"\"\"Calculates the LCS score between mutated sequences and wildtype sequence.\"\"\"\n",
    "    pairwise_lcs = {}\n",
    "    \n",
    "    # Wildtype sequence from the \"wildtype.csv\" file\n",
    "    wildtype_sequence = kinase_orders.get(\"wildtype.csv\", [])\n",
    "    \n",
    "    if not wildtype_sequence:\n",
    "        print(\"Wildtype sequence not found in the kinase orders.\")\n",
    "        return {}\n",
    "\n",
    "    for mutated_sequence in mutated_sequences:\n",
    "        # Look up the kinase order for the mutated sequence file\n",
    "        mutated_file = f\"mutation_{mutated_sequence}.csv\"  # Using the mutated sequence format\n",
    "        mutated_order = next((order for filename, order in kinase_orders.items() if mutated_sequence in filename), None)\n",
    "        \n",
    "        if mutated_order:  # If mutated order is found\n",
    "            lcs_length = longest_common_subsequence(wildtype_sequence, mutated_order)\n",
    "            pairwise_lcs[mutated_sequence] = lcs_length\n",
    "        else:\n",
    "            print(f\"Skipping mutated sequence: {mutated_sequence}, order not found.\")\n",
    "    \n",
    "    # Normalize LCS scores\n",
    "    lcs_scores = list(pairwise_lcs.values())\n",
    "    lcs_min = min(lcs_scores)\n",
    "    lcs_max = max(lcs_scores)\n",
    "\n",
    "    # Prevent division by zero if all scores are the same\n",
    "    if lcs_max - lcs_min == 0:\n",
    "        print(\"All LCS scores are identical. Normalization skipped.\")\n",
    "        normalized_lcs = {seq: 1.0 for seq in pairwise_lcs}  # Assign all a score of 1\n",
    "    else:\n",
    "        normalized_lcs = {seq: (score - lcs_min) / (lcs_max - lcs_min) for seq, score in pairwise_lcs.items()}\n",
    "\n",
    "    return normalized_lcs\n",
    "\n",
    "def display_lcs_tables(normalized_lcs):\n",
    "    \"\"\"Displays two side-by-side tables for LCS scores in two specific ranges.\"\"\"\n",
    "    lcs_groups = {\n",
    "        '0.8-1.0': [],\n",
    "        '0.0-0.3': []\n",
    "    }\n",
    "\n",
    "    # Group the data by the LCS score ranges\n",
    "    for mutated_sequence, normalized_score in normalized_lcs.items():\n",
    "        if 0.8 <= normalized_score <= 1.0:\n",
    "            lcs_groups['0.8-1.0'].append((mutated_sequence, normalized_score))\n",
    "        elif 0.0 <= normalized_score <= 0.3:\n",
    "            lcs_groups['0.0-0.3'].append((mutated_sequence, normalized_score))\n",
    "\n",
    "    # Create side-by-side tables for each LCS group\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "    for idx, (score_group, ax) in enumerate(zip(['0.8-1.0', '0.0-0.3'], axes)):\n",
    "        data = lcs_groups[score_group]\n",
    "\n",
    "        # Only create a table if there is data\n",
    "        if data:\n",
    "            table_data = [(pair[0], f\"{pair[1]:.4f}\") for pair in data]\n",
    "\n",
    "            # Create a table\n",
    "            table = ax.table(cellText=table_data,\n",
    "                            colLabels=[\"Mutated Sequence\", \"Normalized LCS Score\"],\n",
    "                            loc=\"center\",\n",
    "                            cellLoc=\"center\",\n",
    "                            colColours=[\"#f5f5f5\"] * 2)\n",
    "\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"LCS Score: {score_group}\", fontsize=14)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f\"No data for LCS = {score_group}\",\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=12, color='red')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example of using the functions:\n",
    "# Run this once to extract mutated sequences, kinase orders, and calculate LCS scores\n",
    "extract_mutated_sequences()\n",
    "extract_kinase_orders()\n",
    "normalized_lcs = calculate_lcs_scores()\n",
    "\n",
    "# Then you can run the display function whenever you want to show the tables\n",
    "if normalized_lcs:\n",
    "    display_lcs_tables(normalized_lcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Task 5. Using function below. Get a workflow up and running to ping uniprot servers, extract protein sequence \n",
    "in the format needed by kinase library to run the code on extracted sequences. You'll need to import the request library using\n",
    "pip install requests\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id):\n",
    "    '''\n",
    "    Takes in uniprot ID as a string input and pings the Uniprot API to extract genomic coordinates of the protein and exons.\n",
    "    Metadata such as name, taxID, protein sequence, genome assembly name,  ENSEMBL GeneID, ENSEMBL Transcript ID and ENSEMBL Translations IDs is included alongside the extracted coordinates.  \n",
    "\n",
    "    Args:\n",
    "    uniprot_id (str): uniprot ID\n",
    "\n",
    "    Returns:\n",
    "    genomic_information (pd.DataFrame): DataFrame containing genomic coordinates of the protein of interest alongside exon positions and metadata \n",
    "    '''\n",
    "    genomic_information = pd.DataFrame()\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/coordinates/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response_protein.raise_for_status()\n",
    "        \n",
    "        # Load JSON response\n",
    "        response_protein = response_protein.json()\n",
    "        \n",
    "        # Check if response is not empty\n",
    "        if response_protein:\n",
    "            response_protein_normalise = pd.json_normalize(\n",
    "                response_protein, \n",
    "                record_path=['gnCoordinate', 'genomicLocation', 'exon'], \n",
    "                meta=['accession', 'name', 'taxid', 'sequence', \n",
    "                      ['gnCoordinate', 'genomicLocation', 'chromosome'], \n",
    "                      ['gnCoordinate', 'genomicLocation', 'start'], \n",
    "                      ['gnCoordinate', 'genomicLocation', 'end'], \n",
    "                      ['gnCoordinate', 'genomicLocation', 'reverseStrand'], \n",
    "                      ['gnCoordinate', 'genomicLocation', 'nucleotideId'], \n",
    "                      ['gnCoordinate', 'genomicLocation', 'assemblyName'], \n",
    "                      ['gnCoordinate', 'ensemblGeneId'], \n",
    "                      ['gnCoordinate', 'ensemblTranscriptId'], \n",
    "                      ['gnCoordinate', 'ensemblTranslationId']],\n",
    "                record_prefix='exon_'\n",
    "            )\n",
    "\n",
    "            # Group and aggregate exon information\n",
    "            response_protein_normalise = response_protein_normalise.groupby([\n",
    "                'accession', 'name', 'taxid', 'sequence', \n",
    "                'gnCoordinate.genomicLocation.chromosome', \n",
    "                'gnCoordinate.genomicLocation.start', \n",
    "                'gnCoordinate.genomicLocation.end', \n",
    "                'gnCoordinate.genomicLocation.reverseStrand', \n",
    "                'gnCoordinate.genomicLocation.nucleotideId', \n",
    "                'gnCoordinate.genomicLocation.assemblyName', \n",
    "                'gnCoordinate.ensemblGeneId', \n",
    "                'gnCoordinate.ensemblTranscriptId', \n",
    "                'gnCoordinate.ensemblTranslationId'\n",
    "            ]).agg({\n",
    "                'exon_id': lambda x: ','.join(map(str, x)),\n",
    "                'exon_proteinLocation.begin.position': lambda x: ','.join(map(str, x)),                    \n",
    "                'exon_proteinLocation.end.position': lambda x: ','.join(map(str, x)),\n",
    "                'exon_genomeLocation.begin.position': lambda x: ','.join(map(str, x)),                    \n",
    "                'exon_genomeLocation.end.position': lambda x: ','.join(map(str, x))\n",
    "            }).reset_index()\n",
    "\n",
    "            # Concatenate to the main DataFrame\n",
    "            genomic_information = pd.concat([genomic_information, response_protein_normalise], ignore_index=True)\n",
    "        else:\n",
    "            print(f\"No data found for UniProt ID: {uniprot_id}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return genomic_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example usage\n",
    "test_df = extract_genomic_information_from_uniprot_id('O15533')\n",
    "display(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "uniprot_id = ('O95394-1') #modify these to protein of interest\n",
    "reference_position = 61\n",
    "\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    '''\n",
    "    Extracts genomic coordinates and metadata from UniProt, then retrieves a sequence segment\n",
    "    surrounding a specified reference position.\n",
    "    '''\n",
    "    genomic_information = pd.DataFrame()\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response_protein.raise_for_status()\n",
    "        \n",
    "        # Load JSON response\n",
    "        response_protein = response_protein.json()\n",
    "        \n",
    "        # Extract protein sequence\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        \n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Extract 7 amino acids upstream and downstream\n",
    "        start = max(0, reference_position - 7)  # Ensure start is not negative\n",
    "        end = min(len(protein_sequence), reference_position + 8)  # Ensure end is within bounds\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        # Get genomic metadata\n",
    "        genomic_information = {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position,\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "        return genomic_information\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "if result:\n",
    "    print(f\"Extracted Sequence: {result['Extracted_Sequence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'This is me working out how to make this code work for a different sequence, ie the extracted sequence. '\n",
    "'Scroll to the bottom to see this synthesised in one cell with user prompts.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    \"\"\"\n",
    "    Generates all possible single-point mutations for a given amino acid sequence.\n",
    "\n",
    "    Args:\n",
    "        seq_of_interest (str): The original amino acid sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all possible mutated sequences.\n",
    "    \"\"\"\n",
    "    mutated_sequences = []  # List to store mutated sequences\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"  # Standard 20 amino acids\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):  # Iterate over each amino acid\n",
    "        for new_aa in amino_acids:  # Try replacing with each amino acid\n",
    "            if new_aa != original_aa:  # Avoid replacing with itself\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append(mutated_seq)\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "\n",
    "seq_of_interest = \"STIGVMVTASHNPEE\"\n",
    "mutated_sequences = generate_mutated_sequences(seq_of_interest)\n",
    "\n",
    "print(f\"Mutated sequences (# sequences = {len(mutated_sequences)})\")\n",
    "print(mutated_sequences)  # Shows mutations at each position\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"mutations2\", exist_ok=True)\n",
    "#creates a new folder called mutations2 to put the sequence predictions into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kinase_library as kl\n",
    "import pandas as pd\n",
    "\n",
    "seq_of_interest = 'STIGVMVTASHNPEE'  \n",
    "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "mutated_sequences = []  \n",
    "wild_type_filename = f\"mutations2/wildtype2.csv\"\n",
    "\n",
    "\n",
    "# Predict kinase data for the wild-type sequence\n",
    "try:\n",
    "    wild_type_substrate = kl.Substrate(seq_of_interest)\n",
    "    wild_type_predictions = wild_type_substrate.predict()\n",
    "\n",
    "    # Save wild-type predictions to CSV\n",
    "    df_wild_type = pd.DataFrame(wild_type_predictions)\n",
    "    df_wild_type.to_csv(wild_type_filename, index=False)\n",
    "\n",
    "    print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "for i, original_aa in enumerate(seq_of_interest):  \n",
    "    for new_aa in amino_acids:\n",
    "        if new_aa != original_aa:  \n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:] \n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))  \n",
    "\n",
    "\n",
    "print(f\"Total mutations generated: {len(mutated_sequences)}\") \n",
    "\n",
    "for i, original_aa, new_aa, mutated_seq in mutated_sequences: \n",
    "    try:\n",
    "        s = kl.Substrate(mutated_seq)\n",
    "        predictions = s.predict()\n",
    "\n",
    "\n",
    "        df = pd.DataFrame(predictions)\n",
    "\n",
    "        # Save to CSV file with a structured name\n",
    "        filename = f\"mutations2/mutation_Pos{i}_{original_aa}_to_{new_aa}.csv\"\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping mutation at position {i} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "mut_predictions = \"mutations2/\"\n",
    "\n",
    "wildtype_path = os.path.join(mut_predictions, \"wildtype2.csv\")\n",
    "\n",
    "df_wildtype = pd.read_csv(wildtype_path)\n",
    "\n",
    "wildtype_kinase_order = df_wildtype[\"Score Rank\"].tolist()  #extracts kinase orders from the reference sequence\n",
    "\n",
    "kinase_orders = {}\n",
    "\n",
    "#reads all files to extract the kinase orders (except wildtype as that's already been done)\n",
    "for file in os.listdir(mut_predictions):\n",
    "    if file.endswith(\".csv\") and file != \"wildtype.csv\":\n",
    "        file_path = os.path.join(mut_predictions, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            if \"Score Rank\" in df.columns:\n",
    "                kinase_orders[file] = df[\"Score Rank\"].tolist()  # Store kinase order\n",
    "            else:\n",
    "                print(f\"Skipping {file}: No 'Score Rank' column found.\") \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")   #debugging steps\n",
    "\n",
    "print(f\"Extracted kinase orders from {len(kinase_orders)} mutation CSVs.\") \n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "#finds the LCS between wildtype and mut seqs\n",
    "lcs_scores = {}\n",
    "for file, order in kinase_orders.items():\n",
    "    lcs_length = longest_common_subsequence(order, wildtype_kinase_order)\n",
    "    lcs_scores[file] = lcs_length\n",
    "\n",
    "#normalizes LCS scores between 0 and 1\n",
    "if lcs_scores:\n",
    "    lcs_min = min(lcs_scores.values())\n",
    "    lcs_max = max(lcs_scores.values())\n",
    "\n",
    "    normalized_lcs = {file: (score - lcs_min) / (lcs_max - lcs_min) for file, score in lcs_scores.items()}\n",
    "\n",
    "   \n",
    "    df_lcs = pd.DataFrame(list(normalized_lcs.items()), columns=['Mutation_File', 'Normalized_LCS'])\n",
    "    \n",
    "    print(\"\\nNormalized LCS Scores:\")\n",
    "    print(df_lcs.sort_values(by=\"Normalized_LCS\", ascending=True))  # Sort by lowest LCS\n",
    "\n",
    "else:\n",
    "    print(\"No LCS scores calculated. Ensure kinase_orders contains data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "lcs_data = []\n",
    "\n",
    "for file, normalized_score in normalized_lcs.items():\n",
    "    \n",
    "    match = re.match(r\"mutation_Pos(\\d+)_\\w+_to_(\\w+)\\.csv\", file)\n",
    "\n",
    "    if match:\n",
    "        position = int(match.group(1)) \n",
    "        mutated_aa = match.group(2)  \n",
    "\n",
    "        lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "\n",
    "df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "\n",
    "\n",
    "heatmap_matrix = df_lcs.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio')\n",
    "\n",
    "\n",
    "fig = px.imshow(\n",
    "    heatmap_matrix,\n",
    "    labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "    color_continuous_scale='Temps',\n",
    "    title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    ")\n",
    "\n",
    "# Format axes\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='linear',\n",
    "        dtick=1  # Show every position\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='linear',\n",
    "        dtick=1  # Show every position\n",
    "    ),\n",
    "    coloraxis_colorbar=dict(\n",
    "        tickvals=[0, 0.25, 0.5, 0.75, 1],  # Set scale from 0 to 1\n",
    "        ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"]\n",
    "    ),\n",
    "    plot_bgcolor='white'  \n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Fully working function with User Prompts to synthesise a heatmap from a given UniProt ID and reference position'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import kinase_library as kl\n",
    "import requests \n",
    "\n",
    "# Function to extract genomic information from UniProt\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    '''\n",
    "    Extracts genomic coordinates and metadata from UniProt, then retrieves a sequence segment\n",
    "    surrounding a specified reference position.\n",
    "    '''\n",
    "    genomic_information = pd.DataFrame()\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response_protein.raise_for_status()\n",
    "        \n",
    "        # Load JSON response\n",
    "        response_protein = response_protein.json()\n",
    "        \n",
    "        # Extract protein sequence\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        \n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Subtract 1 from the reference position to match indexing (UniProt API is 1-based, so this handles it)\n",
    "        reference_position -= 1  # Convert to 0-based index for Python\n",
    "        \n",
    "        # Extract 7 amino acids upstream and downstream\n",
    "        start = max(0, reference_position - 7)  # Ensure start is not negative\n",
    "        end = min(len(protein_sequence), reference_position + 8)  # Ensure end is within bounds\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        # Get genomic metadata\n",
    "        genomic_information = {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position + 1,  # Return to 1-based indexing for user\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "        return genomic_information\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate all mutated sequences\n",
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    \"\"\"\n",
    "    Generates all possible single-point mutations for a given amino acid sequence.\n",
    "\n",
    "    Args:\n",
    "        seq_of_interest (str): The original amino acid sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all possible mutated sequences.\n",
    "    \"\"\"\n",
    "    mutated_sequences = []  # List to store mutated sequences\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"  # Standard 20 amino acids\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):  # Iterate over each amino acid\n",
    "        for new_aa in amino_acids:  # Try replacing with each amino acid\n",
    "            if new_aa != original_aa:  # Avoid replacing with itself\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "# User input for UniProt ID and reference position\n",
    "uniprot_id = input(\"Enter the UniProt ID: \")\n",
    "reference_position = int(input(\"Enter the reference position: \"))\n",
    "\n",
    "# Extract sequence and genomic data\n",
    "result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "if result:\n",
    "    print(f\"Extracted Sequence: {result['Extracted_Sequence']}\")  # Output the extracted sequence\n",
    "\n",
    "    # Mutate the sequence of interest\n",
    "    mutated_sequences = generate_mutated_sequences(result['Extracted_Sequence'])\n",
    "\n",
    "    print(f\"Mutated sequences (# sequences = {len(mutated_sequences)})\")\n",
    "    print(mutated_sequences)  # Shows mutations at each position\n",
    "\n",
    "    # Set up directory for mutation results\n",
    "    os.makedirs(\"mutations2\", exist_ok=True)\n",
    "\n",
    "    # Wild-type predictions\n",
    "    try:\n",
    "        wild_type_substrate = kl.Substrate(result['Extracted_Sequence'])\n",
    "        wild_type_predictions = wild_type_substrate.predict()\n",
    "\n",
    "        wild_type_filename = f\"mutations2/wildtype2.csv\"\n",
    "        df_wild_type = pd.DataFrame(wild_type_predictions)\n",
    "        df_wild_type.to_csv(wild_type_filename, index=False)\n",
    "\n",
    "        print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "    # Predicting mutated sequences and saving\n",
    "    for i, original_aa, new_aa, mutated_seq in mutated_sequences:  \n",
    "        try:\n",
    "            s = kl.Substrate(mutated_seq)\n",
    "            predictions = s.predict()\n",
    "\n",
    "            df = pd.DataFrame(predictions)\n",
    "\n",
    "            # Save to CSV file with a structured name (corrected format)\n",
    "            filename = f\"mutations2/mutation_Pos{i+1}_{original_aa}_to_{new_aa}.csv\"  # Corrected nomenclature\n",
    "            df.to_csv(filename, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping mutation at position {i+1} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "    # Extract kinase orders from wild-type\n",
    "    wildtype_path = os.path.join(\"mutations2\", \"wildtype2.csv\")\n",
    "    df_wildtype = pd.read_csv(wildtype_path)\n",
    "    wildtype_kinase_order = df_wildtype[\"Score Rank\"].tolist()\n",
    "\n",
    "    kinase_orders = {}\n",
    "    for file in os.listdir(\"mutations2\"):\n",
    "        if file.endswith(\".csv\") and file != \"wildtype2.csv\":\n",
    "            file_path = os.path.join(\"mutations2\", file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                if \"Score Rank\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"Score Rank\"].tolist()\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'Score Rank' column found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    print(f\"Extracted kinase orders from {len(kinase_orders)} mutation CSVs.\")\n",
    "\n",
    "    # Function to compute Longest Common Subsequence (LCS)\n",
    "    def longest_common_subsequence(seq1, seq2):\n",
    "        matcher = SequenceMatcher(None, seq1, seq2)\n",
    "        return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "    # Find LCS between wildtype and mutated sequences\n",
    "    lcs_scores = {}\n",
    "    for file, order in kinase_orders.items():\n",
    "        lcs_length = longest_common_subsequence(order, wildtype_kinase_order)\n",
    "        lcs_scores[file] = lcs_length\n",
    "\n",
    "    # Normalize LCS scores\n",
    "    if lcs_scores:\n",
    "        normalized_lcs = {file: (score - 1) / (310 - 1) for file, score in lcs_scores.items()}\n",
    "\n",
    "\n",
    "        df_lcs = pd.DataFrame(list(normalized_lcs.items()), columns=['Mutation_File', 'Normalized_LCS'])\n",
    "\n",
    "        print(\"\\nNormalized LCS Scores:\")\n",
    "        print(df_lcs.sort_values(by=\"Normalized_LCS\", ascending=True))\n",
    "\n",
    "    # Prepare heatmap of LCS ratios\n",
    "    lcs_data = []\n",
    "    for file, normalized_score in normalized_lcs.items():\n",
    "        match = re.match(r\"mutation_Pos(\\d+)_\\w+_to_(\\w+)\\.csv\", file)\n",
    "\n",
    "        if match:\n",
    "            position = int(match.group(1))  \n",
    "\n",
    "\n",
    "            mutated_aa = match.group(2)\n",
    "\n",
    "            lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "    df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "\n",
    "    # Create heatmap matrix\n",
    "    heatmap_matrix = df_lcs.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "\n",
    "    # Generate heatmap with Plotly\n",
    "    fig = px.imshow(\n",
    "        heatmap_matrix,\n",
    "        labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "        color_continuous_scale='Temps',\n",
    "        title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    "    )\n",
    "\n",
    "    # Create a mapping for the positions\n",
    "position_labels = list(range(-7, 8))  # This creates the range from -7 to +7\n",
    "\n",
    "# Adjust xaxis tickvals and ticktext\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        tickmode='array', \n",
    "        tickvals=list(range(1, 16)),  # Use 1 to 15 for the actual mutation positions\n",
    "        ticktext=position_labels  # Use the custom tick labels (-7 to +7)\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        tickmode='linear',\n",
    "        dtick=1  # Show every position (for y-axis if needed)\n",
    "    ),\n",
    "    coloraxis_colorbar=dict(\n",
    "        tickvals=[0, 0.25, 0.5, 0.75, 1],  # Color bar ticks from 0 to 1\n",
    "        ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "        tickmode='array',  # Ensure it's using the array for ticks\n",
    "        title=\"LCS Ratio\",  # Optional: add a title for the color bar\n",
    "        tickangle=0  # Keep tick labels horizontal\n",
    "    ),\n",
    "    plot_bgcolor='white'  # Background color (optional)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Split the code into functional blocks to facilitate ease of running and storytelling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import kinase_library as kl\n",
    "import requests \n",
    "\n",
    "# Function to extract genomic information from UniProt\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    '''\n",
    "    Extracts genomic coordinates and metadata from UniProt, then retrieves a sequence segment\n",
    "    surrounding a specified reference position.\n",
    "    '''\n",
    "    genomic_information = pd.DataFrame()\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response_protein.raise_for_status()\n",
    "        \n",
    "        # Load JSON response\n",
    "        response_protein = response_protein.json()\n",
    "        \n",
    "        # Extract protein sequence\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        \n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Subtract 1 from the reference position to match indexing (UniProt API is 1-based, so this handles it)\n",
    "        reference_position -= 1  # Convert to 0-based index for Python\n",
    "        \n",
    "        # Extract 7 amino acids upstream and downstream\n",
    "        start = max(0, reference_position - 7)  # Ensure start is not negative\n",
    "        end = min(len(protein_sequence), reference_position + 8)  # Ensure end is within bounds\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        # Get genomic metadata\n",
    "        genomic_information = {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position + 1,  # Return to 1-based indexing for user\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "        return genomic_information\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate all mutated sequences\n",
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    \"\"\"\n",
    "    Generates all possible single-point mutations for a given amino acid sequence.\n",
    "\n",
    "    Args:\n",
    "        seq_of_interest (str): The original amino acid sequence.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all possible mutated sequences.\n",
    "    \"\"\"\n",
    "    mutated_sequences = []  # List to store mutated sequences\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"  # Standard 20 amino acids\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):  # Iterate over each amino acid\n",
    "        for new_aa in amino_acids:  # Try replacing with each amino acid\n",
    "            if new_aa != original_aa:  # Avoid replacing with itself\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "# Function to save wild-type predictions\n",
    "def save_wildtype_predictions(uniprot_id, reference_position, extracted_sequence):\n",
    "    try:\n",
    "        wild_type_substrate = kl.Substrate(extracted_sequence)\n",
    "        wild_type_predictions = wild_type_substrate.predict()\n",
    "\n",
    "        wild_type_filename = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        df_wild_type = pd.DataFrame(wild_type_predictions)\n",
    "        df_wild_type.to_csv(wild_type_filename, index=False)\n",
    "\n",
    "        print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "# Function to save mutated sequences\n",
    "def save_mutated_predictions(mutated_sequences, uniprot_id, reference_position):\n",
    "    for i, original_aa, new_aa, mutated_seq in mutated_sequences:\n",
    "        try:\n",
    "            s = kl.Substrate(mutated_seq)\n",
    "            predictions = s.predict()\n",
    "\n",
    "            df = pd.DataFrame(predictions)\n",
    "\n",
    "            # Save to CSV file with the updated naming convention\n",
    "            filename = f\"mutations2/{uniprot_id}_{reference_position}_mutation_pos{i+1}_{original_aa}_to_{new_aa}.csv\"\n",
    "            df.to_csv(filename, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping mutation at position {i+1} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "# Function to extract kinase orders from CSV files\n",
    "def extract_kinase_orders():\n",
    "    kinase_orders = {}\n",
    "    for file in os.listdir(\"mutations2\"):\n",
    "        if file.endswith(\".csv\") and \"wildtype\" not in file:\n",
    "            file_path = os.path.join(\"mutations2\", file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                if \"Score Rank\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"Score Rank\"].tolist()\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'Score Rank' column found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return kinase_orders\n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "# Function to normalize LCS scores\n",
    "def normalize_lcs_scores(lcs_scores):\n",
    "    return {file: (score - 1) / (310 - 1) for file, score in lcs_scores.items()}\n",
    "\n",
    "# Function to process LCS data for heatmap and save it\n",
    "def process_lcs_for_heatmap(normalized_lcs, uniprot_id):\n",
    "    lcs_data = []\n",
    "    for file, normalized_score in normalized_lcs.items():\n",
    "        match = re.match(r\"mutation_Pos(\\d+)_\\w+_to_(\\w+)\\.csv\", file)\n",
    "\n",
    "        if match:\n",
    "            position = int(match.group(1))  # Get mutation position\n",
    "            mutated_aa = match.group(2)  # Get mutated amino acid\n",
    "\n",
    "            lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "    df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "\n",
    "    # Save LCS data for later use\n",
    "    heatmap_filename = f\"mutations2/{uniprot_id}_heatmap_data.csv\"\n",
    "    df_lcs.to_csv(heatmap_filename, index=False)\n",
    "    print(f\"LCS data saved to {heatmap_filename}\")\n",
    "\n",
    "# Function to render heatmap from processed data\n",
    "def render_heatmap_from_data(heatmap_data):\n",
    "    # Generate heatmap matrix\n",
    "    heatmap_matrix = heatmap_data.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "\n",
    "    # Generate heatmap with Plotly\n",
    "    fig = px.imshow(\n",
    "        heatmap_matrix,\n",
    "        labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "        color_continuous_scale='Temps',\n",
    "        title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    "    )\n",
    "\n",
    "    position_labels = list(range(-7, 8))  # This creates the range from -7 to +7\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            tickmode='array', \n",
    "            tickvals=list(range(1, 16)),  # Use 1 to 15 for the actual mutation positions\n",
    "            ticktext=position_labels  # Use the custom tick labels (-7 to +7)\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickmode='linear',\n",
    "            dtick=1  # Show every position (for y-axis if needed)\n",
    "        ),\n",
    "        coloraxis_colorbar=dict(\n",
    "            tickvals=[\"0, 0.25, 0.5, 0.75, 1\"],  # Color bar ticks from 0 to 1\n",
    "            ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "            tickmode='array',  # Ensure it's using the array for ticks\n",
    "            title=\"LCS Ratio\",  # Optional: add a title for the color bar\n",
    "            tickangle=0  # Keep tick labels horizontal\n",
    "        ),\n",
    "        plot_bgcolor='white'  # Background color \n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "def run_pipeline():\n",
    "    # User input for UniProt ID and reference position\n",
    "    uniprot_id = input(\"Enter the UniProt ID: \")\n",
    "    reference_position = int(input(\"Enter the reference position: \"))\n",
    "\n",
    "    # Extract sequence and genomic data\n",
    "    result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "    if result:\n",
    "        print(f\"Extracted Sequence: {result['Extracted_Sequence']}\")  # Output the extracted sequence\n",
    "\n",
    "        # Mutate the sequence of interest\n",
    "        mutated_sequences = generate_mutated_sequences(result['Extracted_Sequence'])\n",
    "\n",
    "        print(f\"Mutated sequences (# sequences = {len(mutated_sequences)})\")\n",
    "        print(mutated_sequences)  # Shows mutations at each position\n",
    "\n",
    "        # Save wild-type predictions\n",
    "        save_wildtype_predictions(uniprot_id, reference_position, result['Extracted_Sequence'])\n",
    "\n",
    "        # Save mutated sequence predictions\n",
    "        save_mutated_predictions(mutated_sequences, uniprot_id, reference_position)\n",
    "\n",
    "        # Extract kinase orders from mutated CSV files\n",
    "        kinase_orders = extract_kinase_orders()\n",
    "\n",
    "        # Extract kinase order from wildtype\n",
    "        wildtype_path = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        df_wildtype = pd.read_csv(wildtype_path)\n",
    "        wildtype_kinase_order = df_wildtype[\"Score Rank\"].tolist()\n",
    "\n",
    "        # Compute LCS scores between wildtype and mutated sequences\n",
    "        lcs_scores = {}\n",
    "        for file, order in kinase_orders.items():\n",
    "            lcs_length = longest_common_subsequence(order, wildtype_kinase_order)\n",
    "            lcs_scores[file] = lcs_length\n",
    "\n",
    "        # Normalize LCS scores\n",
    "        normalized_lcs = normalize_lcs_scores(lcs_scores)\n",
    "\n",
    "        # Process the LCS data for heatmap and save it to a file\n",
    "        process_lcs_for_heatmap(normalized_lcs, uniprot_id)\n",
    "\n",
    "        # Now, load the processed LCS data for rendering the heatmap\n",
    "        heatmap_data = pd.read_csv(f\"mutations2/{uniprot_id}_heatmap_data.csv\")\n",
    "\n",
    "        # Render the heatmap using the processed data\n",
    "        render_heatmap_from_data(heatmap_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Losing kinase names when saving predictions'\n",
    "'Regex does not extract mutations and positions correctly'\n",
    "##Debugging##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import kinase_library as kl\n",
    "import requests \n",
    "\n",
    "# Function to extract genomic information from UniProt\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    '''\n",
    "    Extracts genomic coordinates and metadata from UniProt, then retrieves a sequence segment\n",
    "    surrounding a specified reference position.\n",
    "    '''\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response_protein.raise_for_status()\n",
    "        \n",
    "        # Load JSON response\n",
    "        response_protein = response_protein.json()\n",
    "        \n",
    "        # Extract protein sequence\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        \n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "        \n",
    "        reference_position -= 1  # Convert to 0-based index for Python\n",
    "        \n",
    "        start = max(0, reference_position - 7)\n",
    "        end = min(len(protein_sequence), reference_position + 8)\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        genomic_information = {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position + 1,\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "        return genomic_information\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate all mutated sequences\n",
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    mutated_sequences = []\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):\n",
    "        for new_aa in amino_acids:\n",
    "            if new_aa != original_aa:\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "# Function to save wild-type predictions\n",
    "def save_wildtype_predictions(uniprot_id, reference_position, extracted_sequence):\n",
    "    try:\n",
    "        wild_type_substrate = kl.Substrate(extracted_sequence)\n",
    "        wild_type_predictions = wild_type_substrate.predict()\n",
    "\n",
    "        wild_type_filename = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        df_wild_type = pd.DataFrame(wild_type_predictions).reset_index()\n",
    "        df_wild_type.to_csv(wild_type_filename, index=False)\n",
    "\n",
    "        print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "# Function to save mutated sequences\n",
    "def save_mutated_predictions(mutated_sequences, uniprot_id, reference_position):\n",
    "    for i, original_aa, new_aa, mutated_seq in mutated_sequences:\n",
    "        try:\n",
    "            s = kl.Substrate(mutated_seq)\n",
    "            predictions = s.predict()\n",
    "\n",
    "            df = pd.DataFrame(predictions).reset_index()\n",
    "\n",
    "            filename = f\"mutations2/{uniprot_id}_{reference_position}_mutation_pos{i+1}_{original_aa}_to_{new_aa}.csv\"\n",
    "            df.to_csv(filename, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping mutation at position {i+1} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "# Function to extract kinase orders from CSV files\n",
    "def extract_kinase_orders():\n",
    "    kinase_orders = {}\n",
    "    for file in os.listdir(\"mutations2\"):\n",
    "        if file.endswith(\".csv\") and \"wildtype\" not in file:\n",
    "            file_path = os.path.join(\"mutations2\", file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                if \"index\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"index\"].tolist()\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'index' column found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return kinase_orders\n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "# Function to normalize LCS scores\n",
    "def normalize_lcs_scores(lcs_scores):\n",
    "    return {file: (score - 1) / (310 - 1) for file, score in lcs_scores.items()}\n",
    "\n",
    "# Function to process LCS data for heatmap and save it\n",
    "def process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position):\n",
    "    lcs_data = []\n",
    "    for file, normalized_score in normalized_lcs.items():\n",
    "        match = re.match(rf\"{uniprot_id}_{reference_position}_mutation_pos(\\d+)_(\\w+)_to_(\\w+)\\.csv\", file)\n",
    "\n",
    "        if match:\n",
    "            position = int(match.group(1))\n",
    "            mutated_aa = match.group(3)\n",
    "\n",
    "            lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "    df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "\n",
    "    heatmap_filename = f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"\n",
    "    df_lcs.to_csv(heatmap_filename, index=False)\n",
    "    print(f\"LCS data saved to {heatmap_filename}\")\n",
    "\n",
    "# Function to render heatmap from processed data\n",
    "def render_heatmap_from_data(heatmap_data):\n",
    "    heatmap_matrix = heatmap_data.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        heatmap_matrix,\n",
    "        labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "        color_continuous_scale='Temps',\n",
    "        title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    "    )\n",
    "\n",
    "    position_labels = list(range(-7, 8))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickmode='array', tickvals=list(range(1, 16)), ticktext=position_labels),\n",
    "        yaxis=dict(tickmode='linear', dtick=1),\n",
    "        coloraxis_colorbar=dict(\n",
    "            tickvals=[0, 0.25, 0.5, 0.75, 1],\n",
    "            ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "            tickmode='array',\n",
    "            title=\"LCS Ratio\",\n",
    "            tickangle=0\n",
    "        ),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Main pipeline function\n",
    "def run_pipeline():\n",
    "    uniprot_id = input(\"Enter the UniProt ID: \")\n",
    "    reference_position = int(input(\"Enter the reference position: \"))\n",
    "\n",
    "    result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "    if result:\n",
    "        mutated_sequences = generate_mutated_sequences(result['Extracted_Sequence'])\n",
    "\n",
    "        save_wildtype_predictions(uniprot_id, reference_position, result['Extracted_Sequence'])\n",
    "        save_mutated_predictions(mutated_sequences, uniprot_id, reference_position)\n",
    "\n",
    "        kinase_orders = extract_kinase_orders()\n",
    "\n",
    "        wildtype_path = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        df_wildtype = pd.read_csv(wildtype_path)\n",
    "\n",
    "        if \"index\" not in df_wildtype.columns:\n",
    "            print(f\"Error: 'index' column not found in {wildtype_path}\")\n",
    "            return\n",
    "\n",
    "        wildtype_kinase_order = df_wildtype[\"index\"].tolist()\n",
    "\n",
    "        lcs_scores = {file: longest_common_subsequence(order, wildtype_kinase_order) for file, order in kinase_orders.items()}\n",
    "        normalized_lcs = normalize_lcs_scores(lcs_scores)\n",
    "\n",
    "        process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position)\n",
    "        render_heatmap_from_data(pd.read_csv(f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Modified for batch input of UniProt ID and Reference Position from Excel File'\n",
    "#Excel file should be named 'input.xlsx' and saved in same directory as the repository\n",
    "#Column headers MUST be 'uniprot_ID' and 'amino_acid_position' (case-sensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import kinase_library as kl\n",
    "import requests \n",
    "\n",
    "# Function to extract genomic information from UniProt\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        response_protein.raise_for_status()\n",
    "        response_protein = response_protein.json()\n",
    "\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "\n",
    "        reference_position -= 1  # Convert to 0-based index for Python\n",
    "        start = max(0, reference_position - 7)\n",
    "        end = min(len(protein_sequence), reference_position + 8)\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        return {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position + 1,\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate all mutated sequences\n",
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    mutated_sequences = []\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):\n",
    "        for new_aa in amino_acids:\n",
    "            if new_aa != original_aa:\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "# Function to save wild-type predictions\n",
    "def save_wildtype_predictions(uniprot_id, reference_position, extracted_sequence):\n",
    "    try:\n",
    "        wild_type_substrate = kl.Substrate(extracted_sequence)\n",
    "        wild_type_predictions = wild_type_substrate.predict()\n",
    "        wild_type_filename = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        pd.DataFrame(wild_type_predictions).reset_index().to_csv(wild_type_filename, index=False)\n",
    "        print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "# Function to save mutated sequences\n",
    "def save_mutated_predictions(mutated_sequences, uniprot_id, reference_position):\n",
    "    for i, original_aa, new_aa, mutated_seq in mutated_sequences:\n",
    "        try:\n",
    "            s = kl.Substrate(mutated_seq)\n",
    "            predictions = s.predict()\n",
    "            filename = f\"mutations2/{uniprot_id}_{reference_position}_mutation_pos{i+1}_{original_aa}_to_{new_aa}.csv\"\n",
    "            pd.DataFrame(predictions).reset_index().to_csv(filename, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping mutation at position {i+1} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "# Function to extract kinase orders from CSV files\n",
    "def extract_kinase_orders():\n",
    "    kinase_orders = {}\n",
    "    for file in os.listdir(\"mutations2\"):\n",
    "        if file.endswith(\".csv\") and \"wildtype\" not in file:\n",
    "            file_path = os.path.join(\"mutations2\", file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Check for the 'index' column first, then 'position' if 'index' is missing\n",
    "                if \"index\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"index\"].tolist()  # Use 'index' column for kinase order\n",
    "                elif \"Position\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"Position\"].tolist()  # Use 'position' column if 'index' is missing\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'index' or 'position' column found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return kinase_orders\n",
    "\n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "# Function to normalize LCS scores\n",
    "def normalize_lcs_scores(lcs_scores):\n",
    "    return {file: (score - 1) / (310 - 1) for file, score in lcs_scores.items()}\n",
    "\n",
    "# Function to process LCS data for heatmap and save it\n",
    "def process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position):\n",
    "    lcs_data = []\n",
    "    for file, normalized_score in normalized_lcs.items():\n",
    "        match = re.match(rf\"{uniprot_id}_{reference_position}_mutation_pos(\\d+)_(\\w+)_to_(\\w+)\\.csv\", file)\n",
    "        if match:\n",
    "            position = int(match.group(1))\n",
    "            mutated_aa = match.group(3)\n",
    "            lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "    df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "    heatmap_filename = f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"\n",
    "    df_lcs.to_csv(heatmap_filename, index=False)\n",
    "    print(f\"LCS data saved to {heatmap_filename}\")\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Function to render heatmap from processed data\n",
    "def render_heatmap_from_data(heatmap_data):\n",
    "    heatmap_matrix = heatmap_data.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        heatmap_matrix,\n",
    "        labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "        color_continuous_scale='Temps',\n",
    "        title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    "    )\n",
    "\n",
    "    position_labels = list(range(-7, 8))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickmode='array', tickvals=list(range(1, 16)), ticktext=position_labels),\n",
    "        yaxis=dict(tickmode='linear', dtick=1),\n",
    "        coloraxis_colorbar=dict(\n",
    "            tickvals=[0, 0.25, 0.5, 0.75, 1],\n",
    "            ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "            tickmode='array',\n",
    "            title=\"LCS Ratio\",\n",
    "            tickangle=0\n",
    "        ),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Main pipeline function\n",
    "def run_pipeline_from_excel(input_file):\n",
    "    # Load the input Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Iterate over each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the UniProt ID and reference position from the row\n",
    "        uniprot_id = row[\"uniprot_ID\"]\n",
    "        reference_position = int(row[\"amino_acid_position\"])\n",
    "\n",
    "        print(f\"Processing {uniprot_id} at position {reference_position}...\")\n",
    "\n",
    "        # Extract genomic information (you need to implement extract_genomic_information_from_uniprot_id)\n",
    "        result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "        if result:\n",
    "            # Generate mutated sequences (you need to implement generate_mutated_sequences)\n",
    "            mutated_sequences = generate_mutated_sequences(result['Extracted_Sequence'])\n",
    "\n",
    "            # Save wildtype and mutated predictions (you need to implement save_wildtype_predictions and save_mutated_predictions)\n",
    "            save_wildtype_predictions(uniprot_id, reference_position, result['Extracted_Sequence'])\n",
    "            save_mutated_predictions(mutated_sequences, uniprot_id, reference_position)\n",
    "\n",
    "            # Extract kinase orders (you need to implement extract_kinase_orders)\n",
    "            kinase_orders = extract_kinase_orders()\n",
    "\n",
    "            # Load the wildtype CSV file\n",
    "            wildtype_path = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "            try:\n",
    "                df_wildtype = pd.read_csv(wildtype_path)\n",
    "\n",
    "                # Check if either \"index\" or \"position\" columns are present\n",
    "                if \"index\" not in df_wildtype.columns and \"position\" not in df_wildtype.columns:\n",
    "                    print(f\"Error: Neither 'index' nor 'position' column found in {wildtype_path}\")\n",
    "                    continue  # Skip this entry and go to the next one\n",
    "\n",
    "                # Use 'index' or 'position' for kinase order\n",
    "                kinase_order_column = \"index\" if \"index\" in df_wildtype.columns else \"position\"\n",
    "                wildtype_kinase_order = df_wildtype[kinase_order_column].tolist()\n",
    "\n",
    "                # Calculate LCS scores\n",
    "                lcs_scores = {file: longest_common_subsequence(order, wildtype_kinase_order) for file, order in kinase_orders.items()}\n",
    "\n",
    "                # Normalize LCS scores (you need to implement normalize_lcs_scores)\n",
    "                normalized_lcs = normalize_lcs_scores(lcs_scores)\n",
    "\n",
    "                # Process LCS for heatmap and save it (you need to implement process_lcs_for_heatmap and render_heatmap_from_data)\n",
    "                process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position)\n",
    "                render_heatmap_from_data(pd.read_csv(f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"))\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: Wildtype file {wildtype_path} not found. Skipping {uniprot_id}.\")\n",
    "                continue  # Skip if the wildtype file is not found\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: No genomic information found for {uniprot_id} at position {reference_position}. Skipping.\")\n",
    "            continue  # Skip to the next UniProt ID if no genomic information is found\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline_from_excel(\"input.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Comparison of two heat maps by position - not pairwise, just like for like positions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "def compare_heatmaps(uniprot_id1, uniprot_id2, reference_position1, reference_position2, directory):\n",
    "    # Construct file paths based on naming convention\n",
    "    heatmap_file1 = os.path.join(directory, f\"{uniprot_id1}_{reference_position1}_heatmap_data.csv\")\n",
    "    heatmap_file2 = os.path.join(directory, f\"{uniprot_id2}_{reference_position2}_heatmap_data.csv\")\n",
    "    \n",
    "    print(f\"Looking for files: {heatmap_file1} and {heatmap_file2}\")\n",
    "    \n",
    "    # Check if both heatmap files exist\n",
    "    if not os.path.exists(heatmap_file1) or not os.path.exists(heatmap_file2):\n",
    "        print(f\"Error: One or both heatmap files for {uniprot_id1}_{reference_position1} or {uniprot_id2}_{reference_position2} do not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Load heatmap data\n",
    "    df1 = pd.read_csv(heatmap_file1)\n",
    "    df2 = pd.read_csv(heatmap_file2)\n",
    "    \n",
    "    # Ensure that both dataframes have the same structure\n",
    "    if not {'Mutation', 'Position', 'LCS_Ratio'}.issubset(df1.columns) or not {'Mutation', 'Position', 'LCS_Ratio'}.issubset(df2.columns):\n",
    "        print(f\"Error: Missing required columns in heatmap data files.\")\n",
    "        return\n",
    "    \n",
    "    # Pivot the data to create a matrix for each heatmap\n",
    "    heatmap_matrix1 = df1.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "    heatmap_matrix2 = df2.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "    \n",
    "    # Ensure both matrices have the same positions\n",
    "    common_positions = heatmap_matrix1.columns.intersection(heatmap_matrix2.columns)\n",
    "    \n",
    "    # Perform t-tests for each common position\n",
    "    p_values = {}\n",
    "    for position in common_positions:\n",
    "        data1 = heatmap_matrix1[position].dropna()\n",
    "        data2 = heatmap_matrix2[position].dropna()\n",
    "        \n",
    "        # Perform t-test only if both groups have data\n",
    "        if len(data1) > 0 and len(data2) > 0:\n",
    "            t_stat, p_val = ttest_ind(data1, data2)\n",
    "            p_values[position] = p_val\n",
    "    \n",
    "    # Save p-values to a CSV file using the desired naming convention\n",
    "    output_file = os.path.join(directory, f\"{uniprot_id1}_{reference_position1}_vs_{uniprot_id2}_{reference_position2}_p_values.csv\")\n",
    "    p_values_df = pd.DataFrame(list(p_values.items()), columns=['Position', 'P-Value'])\n",
    "    p_values_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"P-values comparison saved to {output_file}\")\n",
    "    \n",
    "    # Print positions with p-value smaller than 0.05\n",
    "    significant_positions = p_values_df[p_values_df['P-Value'] < 0.05]\n",
    "    print(\"Significant Positions (p-value < 0.05):\")\n",
    "    print(significant_positions)\n",
    "\n",
    "\n",
    "uniprot_id1 = \"P40337-1\"\n",
    "uniprot_id2 = \"P07954-1\"\n",
    "reference_position1 = 72\n",
    "reference_position2 = 365\n",
    "directory = \"mutations2\"\n",
    "\n",
    "compare_heatmaps(uniprot_id1, uniprot_id2, reference_position1, reference_position2, directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Pairwise T tests for every position between 2 uniprot IDs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "def compare_heatmaps(uniprot_id1, uniprot_id2, reference_position1, reference_position2, directory):\n",
    "    # Construct file paths based on naming convention\n",
    "    heatmap_file1 = os.path.join(directory, f\"{uniprot_id1}_{reference_position1}_heatmap_data.csv\")\n",
    "    heatmap_file2 = os.path.join(directory, f\"{uniprot_id2}_{reference_position2}_heatmap_data.csv\")\n",
    "    \n",
    "    print(f\"Looking for files: {heatmap_file1} and {heatmap_file2}\")\n",
    "    \n",
    "    # Check if both heatmap files exist\n",
    "    if not os.path.exists(heatmap_file1) or not os.path.exists(heatmap_file2):\n",
    "        print(f\"Error: One or both heatmap files for {uniprot_id1}_{reference_position1} or {uniprot_id2}_{reference_position2} do not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Load heatmap data\n",
    "    df1 = pd.read_csv(heatmap_file1)\n",
    "    df2 = pd.read_csv(heatmap_file2)\n",
    "    \n",
    "    # Ensure that both dataframes have the same structure\n",
    "    if not {'Mutation', 'Position', 'LCS_Ratio'}.issubset(df1.columns) or not {'Mutation', 'Position', 'LCS_Ratio'}.issubset(df2.columns):\n",
    "        print(f\"Error: Missing required columns in heatmap data files.\")\n",
    "        return\n",
    "    \n",
    "    # Pivot the data to create a matrix for each heatmap\n",
    "    heatmap_matrix1 = df1.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "    heatmap_matrix2 = df2.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "    \n",
    "    # Perform t-tests for every pair of positions between both heatmaps\n",
    "    p_values = []\n",
    "    for pos1 in heatmap_matrix1.columns:\n",
    "        for pos2 in heatmap_matrix2.columns:\n",
    "            data1 = heatmap_matrix1[pos1].dropna()\n",
    "            data2 = heatmap_matrix2[pos2].dropna()\n",
    "            \n",
    "            # Perform t-test only if both groups have data\n",
    "            if len(data1) > 0 and len(data2) > 0:\n",
    "                t_stat, p_val = ttest_ind(data1, data2)\n",
    "                p_values.append((pos1, pos2, p_val))\n",
    "    \n",
    "    # Convert the list of p-values into a DataFrame\n",
    "    p_values_df = pd.DataFrame(p_values, columns=['Position1', 'Position2', 'P-Value'])\n",
    "    \n",
    "    # Save the p-values to a CSV file using the desired naming convention (with \"pairwise\" at the front)\n",
    "    output_file = os.path.join(directory, f\"pairwise_{uniprot_id1}_{reference_position1}_vs_{uniprot_id2}_{reference_position2}_p_values.csv\")\n",
    "    \n",
    "    # Save all p-values (including those > 0.05)\n",
    "    p_values_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"P-values comparison saved to {output_file}\")\n",
    "    \n",
    "    # Filter positions with p-values smaller than 0.05 and print them\n",
    "    significant_positions = p_values_df[p_values_df['P-Value'] < 0.05]\n",
    "    print(\"Significant Positions (p-value < 0.05):\")\n",
    "    print(significant_positions)\n",
    "\n",
    "uniprot_id1 = \"O95394-1\"\n",
    "uniprot_id2 = \"P40337-1\"\n",
    "reference_position1 = 62\n",
    "reference_position2 = 72\n",
    "directory = \"mutations2\"\n",
    "\n",
    "compare_heatmaps(uniprot_id1, uniprot_id2, reference_position1, reference_position2, directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Some negative values are appearing in the LCS score calculation when mutating from S/Y or T/Y'\n",
    "#Prevents division by zero \n",
    "#Sets min and max values based on that dataset rather than hard-code between 310 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import kinase_library as kl\n",
    "import requests \n",
    "\n",
    "# Function to extract genomic information from UniProt\n",
    "def extract_genomic_information_from_uniprot_id(uniprot_id, reference_position):\n",
    "    try:\n",
    "        print(f'Searching for UniProt ID: {uniprot_id}')\n",
    "        requestURL_protein = f\"https://www.ebi.ac.uk/proteins/api/proteins/{uniprot_id}\"\n",
    "        response_protein = requests.get(requestURL_protein, headers={\"Accept\": \"application/json\"})\n",
    "        response_protein.raise_for_status()\n",
    "        response_protein = response_protein.json()\n",
    "\n",
    "        protein_sequence = response_protein.get(\"sequence\", {}).get(\"sequence\", \"\")\n",
    "        if not protein_sequence:\n",
    "            print(f\"No sequence found for UniProt ID: {uniprot_id}\")\n",
    "            return None\n",
    "\n",
    "        reference_position -= 1  # Convert to 0-based index for Python\n",
    "        start = max(0, reference_position - 7)\n",
    "        end = min(len(protein_sequence), reference_position + 8)\n",
    "        extracted_sequence = protein_sequence[start:end]\n",
    "\n",
    "        return {\n",
    "            \"UniProt_ID\": uniprot_id,\n",
    "            \"Protein_Name\": response_protein.get(\"protein\", {}).get(\"recommendedName\", {}).get(\"fullName\", \"\"),\n",
    "            \"TaxID\": response_protein.get(\"organism\", {}).get(\"taxid\", \"\"),\n",
    "            \"Sequence_Length\": len(protein_sequence),\n",
    "            \"Reference_Position\": reference_position + 1,\n",
    "            \"Extracted_Sequence\": extracted_sequence\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to generate all mutated sequences\n",
    "def generate_mutated_sequences(seq_of_interest):\n",
    "    mutated_sequences = []\n",
    "    amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "    for i, original_aa in enumerate(seq_of_interest):\n",
    "        for new_aa in amino_acids:\n",
    "            if new_aa != original_aa:\n",
    "                mutated_seq = seq_of_interest[:i] + new_aa + seq_of_interest[i+1:]\n",
    "                mutated_sequences.append((i, original_aa, new_aa, mutated_seq))\n",
    "\n",
    "    return mutated_sequences\n",
    "\n",
    "# Function to save wild-type predictions\n",
    "def save_wildtype_predictions(uniprot_id, reference_position, extracted_sequence):\n",
    "    try:\n",
    "        wild_type_substrate = kl.Substrate(extracted_sequence)\n",
    "        wild_type_predictions = wild_type_substrate.predict()\n",
    "        wild_type_filename = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "        pd.DataFrame(wild_type_predictions).reset_index().to_csv(wild_type_filename, index=False)\n",
    "        print(f\"Wild-type sequence predictions saved to {wild_type_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing wild-type sequence: {e}\")\n",
    "\n",
    "# Function to save mutated sequences\n",
    "def save_mutated_predictions(mutated_sequences, uniprot_id, reference_position):\n",
    "    for i, original_aa, new_aa, mutated_seq in mutated_sequences:\n",
    "        try:\n",
    "            s = kl.Substrate(mutated_seq)\n",
    "            predictions = s.predict()\n",
    "            filename = f\"mutations2/{uniprot_id}_{reference_position}_mutation_pos{i+1}_{original_aa}_to_{new_aa}.csv\"\n",
    "            pd.DataFrame(predictions).reset_index().to_csv(filename, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping mutation at position {i+1} ({original_aa} → {new_aa}): {e}\")\n",
    "\n",
    "# Function to extract kinase orders from CSV files\n",
    "def extract_kinase_orders():\n",
    "    kinase_orders = {}\n",
    "    for file in os.listdir(\"mutations2\"):\n",
    "        if file.endswith(\".csv\") and \"wildtype\" not in file:\n",
    "            file_path = os.path.join(\"mutations2\", file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Check for the 'index' column first, then 'position' if 'index' is missing\n",
    "                if \"index\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"index\"].tolist()  # Use 'index' column for kinase order\n",
    "                elif \"Position\" in df.columns:\n",
    "                    kinase_orders[file] = df[\"Position\"].tolist()  # Use 'position' column if 'index' is missing\n",
    "                else:\n",
    "                    print(f\"Skipping {file}: No 'index' or 'position' column found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    return kinase_orders\n",
    "\n",
    "# Function to compute Longest Common Subsequence (LCS)\n",
    "def longest_common_subsequence(seq1, seq2):\n",
    "    matcher = SequenceMatcher(None, seq1, seq2)\n",
    "    return sum(block.size for block in matcher.get_matching_blocks())\n",
    "\n",
    "# ✅ Updated Function to normalize LCS scores safely\n",
    "def normalize_lcs_scores(lcs_scores):\n",
    "    if not lcs_scores:\n",
    "        return {}\n",
    "    \n",
    "    lcs_min = min(lcs_scores.values())\n",
    "    lcs_max = max(lcs_scores.values())\n",
    "\n",
    "    if lcs_max == lcs_min:\n",
    "        return {file: 1.0 for file in lcs_scores}\n",
    "\n",
    "    return {file: (score - lcs_min) / (lcs_max - lcs_min) for file, score in lcs_scores.items()}\n",
    "\n",
    "# Function to process LCS data for heatmap and save it\n",
    "def process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position):\n",
    "    lcs_data = []\n",
    "    for file, normalized_score in normalized_lcs.items():\n",
    "        match = re.match(rf\"{uniprot_id}_{reference_position}_mutation_pos(\\d+)_(\\w+)_to_(\\w+)\\.csv\", file)\n",
    "        if match:\n",
    "            position = int(match.group(1))\n",
    "            mutated_aa = match.group(3)\n",
    "            lcs_data.append([position, mutated_aa, normalized_score])\n",
    "\n",
    "    df_lcs = pd.DataFrame(lcs_data, columns=['Position', 'Mutation', 'LCS_Ratio'])\n",
    "    heatmap_filename = f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"\n",
    "    df_lcs.to_csv(heatmap_filename, index=False)\n",
    "    print(f\"LCS data saved to {heatmap_filename}\")\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Function to render heatmap from processed data\n",
    "def render_heatmap_from_data(heatmap_data):\n",
    "    heatmap_matrix = heatmap_data.pivot_table(index='Mutation', columns='Position', values='LCS_Ratio', aggfunc=np.mean)\n",
    "\n",
    "    fig = px.imshow(\n",
    "        heatmap_matrix,\n",
    "        labels={'x': 'Mutation Position', 'y': 'Mutated Amino Acid', 'color': 'LCS Ratio'},\n",
    "        color_continuous_scale='Temps',\n",
    "        title=\"Heatmap of LCS Ratios for Each Mutation\",\n",
    "    )\n",
    "\n",
    "    position_labels = list(range(-7, 8))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickmode='array', tickvals=list(range(1, 16)), ticktext=position_labels),\n",
    "        yaxis=dict(tickmode='linear', dtick=1),\n",
    "        coloraxis_colorbar=dict(\n",
    "            tickvals=[0, 0.25, 0.5, 0.75, 1],\n",
    "            ticktext=[\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "            tickmode='array',\n",
    "            title=\"LCS Ratio\",\n",
    "            tickangle=0\n",
    "        ),\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Main pipeline function\n",
    "def run_pipeline_from_excel(input_file):\n",
    "    # Load the input Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # Iterate over each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the UniProt ID and reference position from the row\n",
    "        uniprot_id = row[\"uniprot_ID\"]\n",
    "        reference_position = int(row[\"amino_acid_position\"])\n",
    "\n",
    "        print(f\"Processing {uniprot_id} at position {reference_position}...\")\n",
    "\n",
    "        # Extract genomic information\n",
    "        result = extract_genomic_information_from_uniprot_id(uniprot_id, reference_position)\n",
    "\n",
    "        if result:\n",
    "            # Generate mutated sequences\n",
    "            mutated_sequences = generate_mutated_sequences(result['Extracted_Sequence'])\n",
    "\n",
    "            # Save wildtype and mutated predictions\n",
    "            save_wildtype_predictions(uniprot_id, reference_position, result['Extracted_Sequence'])\n",
    "            save_mutated_predictions(mutated_sequences, uniprot_id, reference_position)\n",
    "\n",
    "            # Extract kinase orders\n",
    "            kinase_orders = extract_kinase_orders()\n",
    "\n",
    "            # Load the wildtype CSV file\n",
    "            wildtype_path = f\"mutations2/{uniprot_id}_{reference_position}_wildtype.csv\"\n",
    "            try:\n",
    "                df_wildtype = pd.read_csv(wildtype_path)\n",
    "\n",
    "                # Check if either \"index\" or \"position\" columns are present\n",
    "                if \"index\" not in df_wildtype.columns and \"position\" not in df_wildtype.columns:\n",
    "                    print(f\"Error: Neither 'index' nor 'position' column found in {wildtype_path}\")\n",
    "                    continue  # Skip this entry and go to the next one\n",
    "\n",
    "                # Use 'index' or 'position' for kinase order\n",
    "                kinase_order_column = \"index\" if \"index\" in df_wildtype.columns else \"position\"\n",
    "                wildtype_kinase_order = df_wildtype[kinase_order_column].tolist()\n",
    "\n",
    "                # Calculate LCS scores\n",
    "                lcs_scores = {file: longest_common_subsequence(order, wildtype_kinase_order) for file, order in kinase_orders.items()}\n",
    "\n",
    "                # Normalize LCS scores\n",
    "                normalized_lcs = normalize_lcs_scores(lcs_scores)\n",
    "\n",
    "                # Process LCS for heatmap and save it\n",
    "                process_lcs_for_heatmap(normalized_lcs, uniprot_id, reference_position)\n",
    "                render_heatmap_from_data(pd.read_csv(f\"mutations2/{uniprot_id}_{reference_position}_heatmap_data.csv\"))\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: Wildtype file {wildtype_path} not found. Skipping {uniprot_id}.\")\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: No genomic information found for {uniprot_id} at position {reference_position}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline_from_excel(\"input.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Compare benign and pathogenic mutation LCS scores across mutation and position' \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
